trainer:
  devices: 1
  num_nodes: 1
  max_epochs: 50
  max_steps: -1
  accumulate_grad_batches: 1
  precision: 32
  accelerator: gpu
  strategy: ddp
  log_every_n_steps: 1
  val_check_interval: 1.0
  resume_from_checkpoint: null
  enable_checkpointing: false
  logger: false
model:
  nemo_path: null
  data_dir: ???
  class_labels:
    intent_labels_file: dict.intents.csv
    slot_labels_file: dict.slots.csv
  class_balancing: null
  intent_loss_weight: 0.6
  pad_label: -1
  ignore_extra_tokens: false
  ignore_start_end: true
  train_ds:
    prefix: train
    batch_size: 32
    shuffle: true
    num_samples: -1
    num_workers: 2
    drop_last: false
    pin_memory: false
  validation_ds:
    prefix: test
    batch_size: 32
    shuffle: false
    num_samples: -1
    num_workers: 2
    drop_last: false
    pin_memory: false
  test_ds:
    prefix: test
    batch_size: 32
    shuffle: false
    num_samples: -1
    num_workers: 2
    drop_last: false
    pin_memory: false
  tokenizer:
    tokenizer_name: ${model.language_model.pretrained_model_name}
    vocab_file: null
    tokenizer_model: null
    special_tokens: null
  language_model:
    max_seq_length: 50
    pretrained_model_name: dbmdz/bert-base-turkish-cased
    lm_checkpoint: null
    config_file: null
    config: null
  head:
    num_output_layers: 2
    fc_dropout: 0.1
  optim:
    name: adam
    lr: 2.0e-05
    args:
      name: auto
      params:
        weight_decay: 0.01
    sched:
      name: WarmupAnnealing
      iters_per_batch: null
      max_steps: -1
      monitor: val_loss
      reduce_on_plateau: false
      args:
        name: auto
        params:
          warmup_steps: null
          warmup_ratio: 0.1
          last_epoch: -1
          
model_path: null

exp_manager:
  exp_dir: null
  name: IntentSlot
  create_tensorboard_logger: true
  create_checkpoint_callback: true
hydra:
  run:
    dir: .
  job_logging:
    root:
      handlers: null